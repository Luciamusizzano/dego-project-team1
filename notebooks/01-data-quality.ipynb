{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bebd032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fairlearn in c:\\users\\alero\\miniconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: narwhals>=1.14.0 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from fairlearn) (2.17.0)\n",
      "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from fairlearn) (2.4.2)\n",
      "Requirement already satisfied: pandas>=2.0.3 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from fairlearn) (3.0.1)\n",
      "Requirement already satisfied: scikit-learn>=1.2.1 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from fairlearn) (1.8.0)\n",
      "Requirement already satisfied: scipy<1.16.0,>=1.9.3 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from fairlearn) (1.15.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from pandas>=2.0.3->fairlearn) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\alero\\miniconda3\\lib\\site-packages (from pandas>=2.0.3->fairlearn) (2025.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from scikit-learn>=1.2.1->fairlearn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from scikit-learn>=1.2.1->fairlearn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ff212f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Data manipulation \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "# Fairness \n",
    "from fairlearn.metrics import demographic_parity_difference  # type: ignore\n",
    "# MongoDB \n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b9882",
   "metadata": {},
   "source": [
    "# Data Quality Analysis: NovaCred Credit Applications\n",
    "**Task Force:** Team DEGO\n",
    "**Objective:** Evaluate, quantify, and remediate data quality issues in the `raw_credit_applications.json` dataset across 4 dimensions: Completeness, Consistency, Validity, and Accuracy.\n",
    "\n",
    "## Phase 1: Data Ingestion & Flattening\n",
    "The original dataset is provided in a nested JSON format (e.g., `applicant_info`, `financials`). To perform an effective Exploratory Data Analysis (EDA) using Pandas, our first step is to \"flatten\" this structure, transforming the nested keys into standard tabular columns. We will use the `pd.json_normalize()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95b4883a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 Completed: Data successfully loaded and flattened.\n",
      "Dataset Shape: 502 records (rows) and 21 attributes (columns).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>spending_behavior</th>\n",
       "      <th>processing_timestamp</th>\n",
       "      <th>applicant_info.full_name</th>\n",
       "      <th>applicant_info.email</th>\n",
       "      <th>applicant_info.ssn</th>\n",
       "      <th>applicant_info.ip_address</th>\n",
       "      <th>applicant_info.gender</th>\n",
       "      <th>applicant_info.date_of_birth</th>\n",
       "      <th>applicant_info.zip_code</th>\n",
       "      <th>...</th>\n",
       "      <th>financials.credit_history_months</th>\n",
       "      <th>financials.debt_to_income</th>\n",
       "      <th>financials.savings_balance</th>\n",
       "      <th>decision.loan_approved</th>\n",
       "      <th>decision.rejection_reason</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>decision.interest_rate</th>\n",
       "      <th>decision.approved_amount</th>\n",
       "      <th>financials.annual_salary</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>app_200</td>\n",
       "      <td>[{'category': 'Shopping', 'amount': 480}, {'ca...</td>\n",
       "      <td>2024-01-15T00:00:00Z</td>\n",
       "      <td>Jerry Smith</td>\n",
       "      <td>jerry.smith17@hotmail.com</td>\n",
       "      <td>596-64-4340</td>\n",
       "      <td>192.168.48.155</td>\n",
       "      <td>Male</td>\n",
       "      <td>2001-03-09</td>\n",
       "      <td>10036</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.20</td>\n",
       "      <td>31212</td>\n",
       "      <td>False</td>\n",
       "      <td>algorithm_risk_score</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_037</td>\n",
       "      <td>[{'category': 'Rent', 'amount': 608}, {'catego...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brandon Walker</td>\n",
       "      <td>brandon.walker2@yahoo.com</td>\n",
       "      <td>425-69-4784</td>\n",
       "      <td>10.1.102.112</td>\n",
       "      <td>M</td>\n",
       "      <td>1992-03-31</td>\n",
       "      <td>10032</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.18</td>\n",
       "      <td>17915</td>\n",
       "      <td>False</td>\n",
       "      <td>algorithm_risk_score</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_215</td>\n",
       "      <td>[{'category': 'Rent', 'amount': 109}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scott Moore</td>\n",
       "      <td>scott.moore94@mail.com</td>\n",
       "      <td>370-78-5178</td>\n",
       "      <td>10.240.193.250</td>\n",
       "      <td>Male</td>\n",
       "      <td>1989-10-24</td>\n",
       "      <td>10075</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>0.21</td>\n",
       "      <td>37909</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vacation</td>\n",
       "      <td>3.7</td>\n",
       "      <td>59000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>app_024</td>\n",
       "      <td>[{'category': 'Fitness', 'amount': 575}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thomas Lee</td>\n",
       "      <td>thomas.lee6@protonmail.com</td>\n",
       "      <td>194-35-1833</td>\n",
       "      <td>192.168.175.67</td>\n",
       "      <td>Male</td>\n",
       "      <td>1983-04-25</td>\n",
       "      <td>10077</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.3</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>app_184</td>\n",
       "      <td>[{'category': 'Entertainment', 'amount': 463}]</td>\n",
       "      <td>2024-01-15T00:00:00Z</td>\n",
       "      <td>Brian Rodriguez</td>\n",
       "      <td>brian.rodriguez86@aol.com</td>\n",
       "      <td>480-41-2475</td>\n",
       "      <td>172.29.125.105</td>\n",
       "      <td>M</td>\n",
       "      <td>1999-05-21</td>\n",
       "      <td>10080</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.23</td>\n",
       "      <td>31763</td>\n",
       "      <td>False</td>\n",
       "      <td>algorithm_risk_score</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       _id                                  spending_behavior  \\\n",
       "0  app_200  [{'category': 'Shopping', 'amount': 480}, {'ca...   \n",
       "1  app_037  [{'category': 'Rent', 'amount': 608}, {'catego...   \n",
       "2  app_215              [{'category': 'Rent', 'amount': 109}]   \n",
       "3  app_024           [{'category': 'Fitness', 'amount': 575}]   \n",
       "4  app_184     [{'category': 'Entertainment', 'amount': 463}]   \n",
       "\n",
       "   processing_timestamp applicant_info.full_name        applicant_info.email  \\\n",
       "0  2024-01-15T00:00:00Z              Jerry Smith   jerry.smith17@hotmail.com   \n",
       "1                   NaN           Brandon Walker   brandon.walker2@yahoo.com   \n",
       "2                   NaN              Scott Moore      scott.moore94@mail.com   \n",
       "3                   NaN               Thomas Lee  thomas.lee6@protonmail.com   \n",
       "4  2024-01-15T00:00:00Z          Brian Rodriguez   brian.rodriguez86@aol.com   \n",
       "\n",
       "  applicant_info.ssn applicant_info.ip_address applicant_info.gender  \\\n",
       "0        596-64-4340            192.168.48.155                  Male   \n",
       "1        425-69-4784              10.1.102.112                     M   \n",
       "2        370-78-5178            10.240.193.250                  Male   \n",
       "3        194-35-1833            192.168.175.67                  Male   \n",
       "4        480-41-2475            172.29.125.105                     M   \n",
       "\n",
       "  applicant_info.date_of_birth applicant_info.zip_code  ...  \\\n",
       "0                   2001-03-09                   10036  ...   \n",
       "1                   1992-03-31                   10032  ...   \n",
       "2                   1989-10-24                   10075  ...   \n",
       "3                   1983-04-25                   10077  ...   \n",
       "4                   1999-05-21                   10080  ...   \n",
       "\n",
       "  financials.credit_history_months  financials.debt_to_income  \\\n",
       "0                               23                       0.20   \n",
       "1                               51                       0.18   \n",
       "2                               41                       0.21   \n",
       "3                               70                       0.35   \n",
       "4                               14                       0.23   \n",
       "\n",
       "   financials.savings_balance  decision.loan_approved  \\\n",
       "0                       31212                   False   \n",
       "1                       17915                   False   \n",
       "2                       37909                    True   \n",
       "3                           0                    True   \n",
       "4                       31763                   False   \n",
       "\n",
       "   decision.rejection_reason loan_purpose decision.interest_rate  \\\n",
       "0       algorithm_risk_score          NaN                    NaN   \n",
       "1       algorithm_risk_score          NaN                    NaN   \n",
       "2                        NaN     vacation                    3.7   \n",
       "3                        NaN          NaN                    4.3   \n",
       "4       algorithm_risk_score          NaN                    NaN   \n",
       "\n",
       "   decision.approved_amount  financials.annual_salary  notes  \n",
       "0                       NaN                       NaN    NaN  \n",
       "1                       NaN                       NaN    NaN  \n",
       "2                   59000.0                       NaN    NaN  \n",
       "3                   34000.0                       NaN    NaN  \n",
       "4                       NaN                       NaN    NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = '../data/raw/raw_credit_applications.json'\n",
    "\n",
    "# Uploading the JSON file\n",
    "with open(file_path, 'r') as file:\n",
    "    raw_data = json.load(file)\n",
    "\n",
    "# Flattening: let's extract the nested dictionaries in single columns\n",
    "df = pd.json_normalize(raw_data)\n",
    "\n",
    "print(\"Phase 1 Completed: Data successfully loaded and flattened.\")\n",
    "print(f\"Dataset Shape: {df.shape[0]} records (rows) and {df.shape[1]} attributes (columns).\")\n",
    "\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cee78f",
   "metadata": {},
   "source": [
    "## Phase 2: Systematic Data Profiling (Discovery)\n",
    "In the real world, we cannot assume we know the data's flaws. We must build systematic checks to discover issues across the four dimensions of Data Quality.\n",
    "\n",
    "1. **Completeness Profiler**: Standard `.isnull()` checks, plus a scanner for \"hidden\" nulls (empty strings, whitespace, 'N/A').\n",
    "2. **Consistency Profiler**: Checking data types against expected schemas and analyzing unique values in categorical fields to spot variations (e.g., 'M' vs 'Male').\n",
    "3. **Validity & Accuracy Profiler**: Using statistical summaries to find impossible values (e.g., negative ages) and checking for logical duplicates (e.g., same SSN for different users)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ae9a3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1. COMPLETENESS DISCOVERY ===\n",
      "Columns with missing data detected:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standard Nulls</th>\n",
       "      <th>Hidden Nulls (Empty Strings)</th>\n",
       "      <th>Total Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>notes</th>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.annual_salary</th>\n",
       "      <td>497</td>\n",
       "      <td>0</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_purpose</th>\n",
       "      <td>452</td>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>processing_timestamp</th>\n",
       "      <td>440</td>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.rejection_reason</th>\n",
       "      <td>292</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.approved_amount</th>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.interest_rate</th>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.email</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.ip_address</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.ssn</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.annual_income</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.date_of_birth</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.gender</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.zip_code</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Standard Nulls  Hidden Nulls (Empty Strings)  \\\n",
       "notes                                    500                             0   \n",
       "financials.annual_salary                 497                             0   \n",
       "loan_purpose                             452                             0   \n",
       "processing_timestamp                     440                             0   \n",
       "decision.rejection_reason                292                             0   \n",
       "decision.approved_amount                 210                             0   \n",
       "decision.interest_rate                   210                             0   \n",
       "applicant_info.email                       0                             7   \n",
       "applicant_info.ip_address                  5                             0   \n",
       "applicant_info.ssn                         5                             0   \n",
       "financials.annual_income                   5                             0   \n",
       "applicant_info.date_of_birth               1                             4   \n",
       "applicant_info.gender                      1                             2   \n",
       "applicant_info.zip_code                    1                             1   \n",
       "\n",
       "                              Total Missing  \n",
       "notes                                   500  \n",
       "financials.annual_salary                497  \n",
       "loan_purpose                            452  \n",
       "processing_timestamp                    440  \n",
       "decision.rejection_reason               292  \n",
       "decision.approved_amount                210  \n",
       "decision.interest_rate                  210  \n",
       "applicant_info.email                      7  \n",
       "applicant_info.ip_address                 5  \n",
       "applicant_info.ssn                        5  \n",
       "financials.annual_income                  5  \n",
       "applicant_info.date_of_birth              5  \n",
       "applicant_info.gender                     3  \n",
       "applicant_info.zip_code                   2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 2. CONSISTENCY DISCOVERY ===\n",
      "Data Types Overview:\n",
      "spending_behavior           object\n",
      "financials.annual_income    object\n",
      "dtype: object\n",
      "\n",
      "Unique values in 'applicant_info.gender':\n",
      "<StringArray>\n",
      "['Male', 'M', 'F', 'Female', '']\n",
      "Length: 5, dtype: str\n",
      "\n",
      "Unique values in 'decision.rejection_reason':\n",
      "<StringArray>\n",
      "[       'algorithm_risk_score', 'insufficient_credit_history',\n",
      "              'high_dti_ratio',                  'low_income']\n",
      "Length: 4, dtype: str\n",
      "\n",
      "=== 3. VALIDITY & ACCURACY DISCOVERY ===\n",
      "Statistical Summary for Numeric Columns (Look at min/max):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>financials.credit_history_months</th>\n",
       "      <td>-10.00</td>\n",
       "      <td>133.00</td>\n",
       "      <td>50.402390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.debt_to_income</th>\n",
       "      <td>0.05</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.246195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.savings_balance</th>\n",
       "      <td>-5000.00</td>\n",
       "      <td>88078.00</td>\n",
       "      <td>29493.503984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.interest_rate</th>\n",
       "      <td>2.50</td>\n",
       "      <td>6.50</td>\n",
       "      <td>4.564726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.approved_amount</th>\n",
       "      <td>15000.00</td>\n",
       "      <td>80000.00</td>\n",
       "      <td>47845.890411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.annual_salary</th>\n",
       "      <td>45000.00</td>\n",
       "      <td>94000.00</td>\n",
       "      <td>69200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       min       max          mean\n",
       "financials.credit_history_months    -10.00    133.00     50.402390\n",
       "financials.debt_to_income             0.05      1.85      0.246195\n",
       "financials.savings_balance        -5000.00  88078.00  29493.503984\n",
       "decision.interest_rate                2.50      6.50      4.564726\n",
       "decision.approved_amount          15000.00  80000.00  47845.890411\n",
       "financials.annual_salary          45000.00  94000.00  69200.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 3 unique SSNs that are shared across 11 different records!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 1. COMPLETENESS DISCOVERY ===\")\n",
    "# Standard nulls\n",
    "standard_nulls = df.isnull().sum()\n",
    "\n",
    "# Scanner for hidden nulls (strings that are just spaces or empty)\n",
    "hidden_nulls = df.map(lambda x: str(x).strip() == '').sum()\n",
    "\n",
    "completeness_df = pd.DataFrame({\n",
    "    'Standard Nulls': standard_nulls,\n",
    "    'Hidden Nulls (Empty Strings)': hidden_nulls,\n",
    "    'Total Missing': standard_nulls + hidden_nulls\n",
    "})\n",
    "print(\"Columns with missing data detected:\")\n",
    "display(completeness_df[completeness_df['Total Missing'] > 0].sort_values(by='Total Missing', ascending=False))\n",
    "\n",
    "\n",
    "print(\"\\n=== 2. CONSISTENCY DISCOVERY ===\")\n",
    "# Check data types to find mismatches (e.g., numbers stored as strings)\n",
    "print(\"Data Types Overview:\")\n",
    "print(df.dtypes[df.dtypes == 'object']) # Focusing on object/string columns\n",
    "\n",
    "# Check unique values for categorical columns to spot formatting inconsistencies\n",
    "categorical_cols = ['applicant_info.gender', 'decision.rejection_reason']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\nUnique values in '{col}':\")\n",
    "        print(df[col].dropna().unique())\n",
    "\n",
    "\n",
    "print(\"\\n=== 3. VALIDITY & ACCURACY DISCOVERY ===\")\n",
    "# Statistical summary to spot impossible min/max values (e.g., negatives)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "print(\"Statistical Summary for Numeric Columns (Look at min/max):\")\n",
    "display(df[numeric_cols].describe().T[['min', 'max', 'mean']])\n",
    "\n",
    "# Logical Duplicates Check (SSN is a primary identifier, it should be unique)\n",
    "if 'applicant_info.ssn' in df.columns:\n",
    "    duplicate_ssns = df[df.duplicated(subset=['applicant_info.ssn'], keep=False)]\n",
    "    print(f\"\\nFound {duplicate_ssns['applicant_info.ssn'].nunique()} unique SSNs that are shared across {len(duplicate_ssns)} different records!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b963bd2c",
   "metadata": {},
   "source": [
    "### Phase 2.5: Deep Dive Profiling (Domain-Specific Checks)\n",
    "To ensure maximum Data Quality, we must go beyond basic statistical profiling and check domain-specific business rules:\n",
    "4. **Format Validation**: Using Regex to ensure SSNs, Emails, and IPs follow standard patterns.\n",
    "5. **Cross-Field Logic**: Ensuring the loan decision logic (`approved` vs `rejected` fields) does not contradict itself.\n",
    "6. **Nested Array Inspection**: Unpacking the `spending_behavior` array to check for anomalous spending amounts.\n",
    "7. **Temporal Logic**: Checking for impossible birth dates.\n",
    "8. **Final verification**: Checking for exact duplicate records, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "838e644d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 4. FORMAT VALIDITY (REGEX CHECKS) ===\n",
      "Found 11 malformed emails.\n",
      "26                           \n",
      "138    mike johnson@gmail.com\n",
      "181     test.user.outlook.com\n",
      "187                          \n",
      "275                          \n",
      "Name: applicant_info.email, dtype: str\n",
      "\n",
      "Found 0 malformed SSNs.\n",
      "\n",
      "=== 5. CROSS-COLUMN LOGICAL VALIDITY ===\n",
      "Contradiction (Approved but rejected): 0 rows\n",
      "Contradiction (Rejected but has approved amount): 0 rows\n",
      "\n",
      "=== 6. NESTED DATA INSPECTION (SPENDING BEHAVIOR) ===\n",
      "Found 0 negative spending amounts in the nested arrays!\n",
      "\n",
      "=== 7. TEMPORAL ACCURACY ===\n",
      "Found 0 birth dates in the future.\n",
      "Found 0 applicants appearing to be underage (< 18).\n",
      "\n",
      "=== 8. FINAL VERIFICATION ===\n",
      "Found 0 exact duplicate records.\n",
      "\n",
      "Row-by-row data types in 'annual_income':\n",
      "financials.annual_income\n",
      "<class 'int'>      488\n",
      "<class 'str'>        8\n",
      "<class 'float'>      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of Inconsistent Date Formats in 'date_of_birth':\n",
      "<StringArray>\n",
      "['2001-03-09', '1992-03-31', '14/02/1982', '28/01/1990']\n",
      "Length: 4, dtype: str\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 4. FORMAT VALIDITY (REGEX CHECKS) ===\")\n",
    "# Check for malformed emails\n",
    "email_regex = r\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"\n",
    "if 'applicant_info.email' in df.columns:\n",
    "    valid_emails = df['applicant_info.email'].dropna().apply(lambda x: bool(re.match(email_regex, str(x))))\n",
    "    invalid_emails = df['applicant_info.email'].dropna()[~valid_emails]\n",
    "    print(f\"Found {len(invalid_emails)} malformed emails.\")\n",
    "    if len(invalid_emails) > 0: print(invalid_emails.head())\n",
    "\n",
    "# Check for malformed SSNs (expecting XXX-XX-XXXX)\n",
    "ssn_regex = r\"^\\d{3}-\\d{2}-\\d{4}$\"\n",
    "if 'applicant_info.ssn' in df.columns:\n",
    "    valid_ssns = df['applicant_info.ssn'].dropna().apply(lambda x: bool(re.match(ssn_regex, str(x))))\n",
    "    invalid_ssns = df['applicant_info.ssn'].dropna()[~valid_ssns]\n",
    "    print(f\"\\nFound {len(invalid_ssns)} malformed SSNs.\")\n",
    "\n",
    "\n",
    "print(\"\\n=== 5. CROSS-COLUMN LOGICAL VALIDITY ===\")\n",
    "# Contradiction: Loan approved BUT has a rejection reason\n",
    "contradiction_1 = df[(df['decision.loan_approved'] == True) & (df['decision.rejection_reason'].notnull())]\n",
    "print(f\"Contradiction (Approved but rejected): {len(contradiction_1)} rows\")\n",
    "\n",
    "# Contradiction: Loan rejected BUT has an approved amount\n",
    "contradiction_2 = df[(df['decision.loan_approved'] == False) & (df['decision.approved_amount'].notnull())]\n",
    "print(f\"Contradiction (Rejected but has approved amount): {len(contradiction_2)} rows\")\n",
    "\n",
    "\n",
    "print(\"\\n=== 6. NESTED DATA INSPECTION (SPENDING BEHAVIOR) ===\")\n",
    "# We need to \"explode\" the list of dictionaries to inspect the amounts\n",
    "if 'spending_behavior' in df.columns:\n",
    "    exploded_spending = df.explode('spending_behavior')\n",
    "    # Extract the 'amount' from the dictionary, ignoring NaNs\n",
    "    spending_amounts = exploded_spending['spending_behavior'].dropna().apply(lambda x: x.get('amount') if isinstance(x, dict) else np.nan)\n",
    "    \n",
    "    negative_spending = spending_amounts[spending_amounts < 0]\n",
    "    print(f\"Found {len(negative_spending)} negative spending amounts in the nested arrays!\")\n",
    "\n",
    "\n",
    "print(\"\\n=== 7. TEMPORAL ACCURACY ===\")\n",
    "if 'applicant_info.date_of_birth' in df.columns:\n",
    "    # Convert to datetime just for checking (handling mixed formats safely with coerce to catch unparseable ones)\n",
    "    temp_dob = pd.to_datetime(df['applicant_info.date_of_birth'], format='mixed', errors='coerce')\n",
    "    \n",
    "    # Check for dates in the future\n",
    "    future_dates = temp_dob[temp_dob > pd.Timestamp.now()]\n",
    "    print(f\"Found {len(future_dates)} birth dates in the future.\")\n",
    "    \n",
    "    # Check for unrealistic ages (e.g., born after 2008 -> under 18)\n",
    "    underage = temp_dob[temp_dob > pd.Timestamp('2008-01-01')]\n",
    "    print(f\"Found {len(underage)} applicants appearing to be underage (< 18).\")\n",
    "\n",
    "\n",
    "print(\"\\n=== 8. FINAL VERIFICATION ===\")\n",
    "\n",
    "# 1. Exact Duplicate Records\n",
    "# Checking if any entire row is a 1:1 copy of another\n",
    "exact_duplicates = df[df.astype(str).duplicated(keep=False)]\n",
    "print(f\"Found {len(exact_duplicates)} exact duplicate records.\")\n",
    "\n",
    "# 2. Inconsistent Data Types Across Records\n",
    "# Checking the Python type of each individual cell in a problematic column\n",
    "if 'financials.annual_income' in df.columns:\n",
    "    print(\"\\nRow-by-row data types in 'annual_income':\")\n",
    "    type_counts = df['financials.annual_income'].dropna().apply(type).value_counts()\n",
    "    print(type_counts)\n",
    "\n",
    "# 3. Inconsistent Date Formats\n",
    "# Printing a sample to visually prove the formatting clash\n",
    "if 'applicant_info.date_of_birth' in df.columns:\n",
    "    print(\"\\nSample of Inconsistent Date Formats in 'date_of_birth':\")\n",
    "    # Grabbing a mix of rows to show the discrepancy\n",
    "    sample_dates = df['applicant_info.date_of_birth'].dropna().iloc[[0, 1, 5, 6]].values\n",
    "    print(sample_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d116a",
   "metadata": {},
   "source": [
    "## Phase 3: Data Remediation (Cleaning Pipeline)\n",
    "Based on our systematic profiling, we will now apply a data cleaning pipeline to resolve all identified issues, ensuring the dataset is ready for the Bias Detection and Privacy phases.\n",
    "\n",
    "**Remediation Strategies by Dimension:**\n",
    "1. **Accuracy (Duplicates)**: Drop exact row duplicates. Because of unhashable lists, we will use string conversion for the duplication mask.\n",
    "2. **Consistency (Formatting & Schema)**: \n",
    "   - Standardize `gender` to 'Male' and 'Female'.\n",
    "   - Consolidate the misaligned `annual_salary` column into `annual_income`.\n",
    "   - Cast `annual_income` to numeric float values.\n",
    "   - Standardize `date_of_birth` to uniform pandas `datetime` objects.\n",
    "3. **Validity (Impossible Values)**:\n",
    "   - Convert negative `credit_history_months` to `NaN` (treating them as data entry errors).\n",
    "   - Clean the nested `spending_behavior` arrays by removing dictionaries with negative amounts.\n",
    "4. **Completeness (Imputation)**:\n",
    "   - Fill missing numeric values (like the newly created NaNs in credit history or missing income) with the median to avoid losing records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4adbf692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Data Remediation Pipeline...\n",
      "Dropped 0 exact duplicate rows.\n",
      "Merged 'annual_salary' into 'annual_income' and dropped redundant column.\n",
      "Cast 'annual_income' to numeric.\n",
      "Standardized 'gender' formats.\n",
      "Standardized 'date_of_birth' to datetime objects.\n",
      "Replaced 2 negative credit history values with NaN.\n",
      "Removed negative spending amounts from nested arrays.\n",
      "Imputed missing numeric values with column medians.\n",
      "\n",
      "=== REMEDIATION COMPLETE ===\n",
      "Final Cleaned Dataset Shape: 502 records and 20 attributes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Data Remediation Pipeline...\")\n",
    "\n",
    "# Make a copy to preserve the original flattened dataframe\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 1. ACCURACY: Drop Exact Duplicates\n",
    "# We use the string casting trick to find and drop exact duplicate rows\n",
    "duplicate_mask = df_clean.astype(str).duplicated()\n",
    "df_clean = df_clean[~duplicate_mask]\n",
    "print(f\"Dropped {duplicate_mask.sum()} exact duplicate rows.\")\n",
    "\n",
    "\n",
    "# 2. CONSISTENCY: Schema, Types, and Formatting\n",
    "# Schema consolidation\n",
    "if 'financials.annual_salary' in df_clean.columns:\n",
    "    df_clean['financials.annual_income'] = df_clean['financials.annual_income'].fillna(df_clean['financials.annual_salary'])\n",
    "    df_clean.drop(columns=['financials.annual_salary'], inplace=True)\n",
    "    print(\"Merged 'annual_salary' into 'annual_income' and dropped redundant column.\")\n",
    "\n",
    "# Type casting\n",
    "df_clean['financials.annual_income'] = pd.to_numeric(df_clean['financials.annual_income'], errors='coerce')\n",
    "print(\"Cast 'annual_income' to numeric.\")\n",
    "\n",
    "# Gender standardization\n",
    "df_clean['applicant_info.gender'] = df_clean['applicant_info.gender'].replace({'M': 'Male', 'F': 'Female'})\n",
    "print(\"Standardized 'gender' formats.\")\n",
    "\n",
    "# Date standardization\n",
    "df_clean['applicant_info.date_of_birth'] = pd.to_datetime(df_clean['applicant_info.date_of_birth'], format='mixed', errors='coerce')\n",
    "print(\"Standardized 'date_of_birth' to datetime objects.\")\n",
    "\n",
    "\n",
    "# 3. VALIDITY: Impossible Values\n",
    "# Fix negative credit history (set to NaN for later imputation)\n",
    "invalid_credit_mask = df_clean['financials.credit_history_months'] < 0\n",
    "df_clean.loc[invalid_credit_mask, 'financials.credit_history_months'] = np.nan\n",
    "print(f\"Replaced {invalid_credit_mask.sum()} negative credit history values with NaN.\")\n",
    "\n",
    "# Fix nested negative spending\n",
    "def clean_spending(spending_list):\n",
    "    if not isinstance(spending_list, list): return spending_list\n",
    "    # Keep only items where 'amount' is >= 0\n",
    "    return [item for item in spending_list if isinstance(item, dict) and item.get('amount', 0) >= 0]\n",
    "\n",
    "df_clean['spending_behavior'] = df_clean['spending_behavior'].apply(clean_spending)\n",
    "print(\"Removed negative spending amounts from nested arrays.\")\n",
    "\n",
    "\n",
    "# 4. COMPLETENESS: Handling Missing Data\n",
    "# Impute missing numeric values with median (robust to outliers)\n",
    "numeric_cols_to_impute = ['financials.annual_income', 'financials.credit_history_months']\n",
    "for col in numeric_cols_to_impute:\n",
    "    median_val = df_clean[col].median()\n",
    "    df_clean[col] = df_clean[col].fillna(median_val)\n",
    "print(\"Imputed missing numeric values with column medians.\")\n",
    "\n",
    "# Categorical missing values (e.g., gender, missing emails) \n",
    "# We'll label missing categorical values as 'Unknown' to explicitly track them\n",
    "df_clean['applicant_info.gender'] = df_clean['applicant_info.gender'].fillna('Unknown')\n",
    "\n",
    "print(\"\\n=== REMEDIATION COMPLETE ===\")\n",
    "print(f\"Final Cleaned Dataset Shape: {df_clean.shape[0]} records and {df_clean.shape[1]} attributes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
