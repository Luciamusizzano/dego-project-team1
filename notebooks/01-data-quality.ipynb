{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bebd032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fairlearn in c:\\users\\alero\\miniconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: narwhals>=1.14.0 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from fairlearn) (2.17.0)\n",
      "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from fairlearn) (2.4.2)\n",
      "Requirement already satisfied: pandas>=2.0.3 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from fairlearn) (3.0.1)\n",
      "Requirement already satisfied: scikit-learn>=1.2.1 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from fairlearn) (1.8.0)\n",
      "Requirement already satisfied: scipy<1.16.0,>=1.9.3 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from fairlearn) (1.15.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from pandas>=2.0.3->fairlearn) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\alero\\miniconda3\\lib\\site-packages (from pandas>=2.0.3->fairlearn) (2025.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from scikit-learn>=1.2.1->fairlearn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from scikit-learn>=1.2.1->fairlearn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alero\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ff212f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Data manipulation \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "# Fairness \n",
    "from fairlearn.metrics import demographic_parity_difference  # type: ignore\n",
    "# MongoDB \n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b9882",
   "metadata": {},
   "source": [
    "# Data Quality Analysis: NovaCred Credit Applications\n",
    "**Task Force:** Team DEGO\n",
    "**Objective:** Evaluate, quantify, and remediate data quality issues in the `raw_credit_applications.json` dataset across 4 dimensions: Completeness, Consistency, Validity, and Accuracy.\n",
    "\n",
    "## Phase 1: Data Ingestion & Flattening\n",
    "The original dataset is provided in a nested JSON format (e.g., `applicant_info`, `financials`). To perform an effective Exploratory Data Analysis (EDA) using Pandas, our first step is to \"flatten\" this structure, transforming the nested keys into standard tabular columns. We will use the `pd.json_normalize()` function.\n",
    "\n",
    "To facilitate the Data Scientist's \"Proxy Discrimination Analysis\", we must transform the nested `spending_behavior` array into standard numerical features. We will pivot the categories into individual columns (e.g., `spending_Rent`, `spending_Healthcare`), allowing for direct correlation and statistical testing against the `loan_approved` outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95b4883a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PHASE 1: DATA INGESTION & ADVANCED FLATTENING ===\n",
      "Unpacking nested spending behaviors...\n",
      "Data successfully loaded and flattened.\n",
      "Dataset Shape: 502 records and 35 attributes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>processing_timestamp</th>\n",
       "      <th>applicant_info.full_name</th>\n",
       "      <th>applicant_info.email</th>\n",
       "      <th>applicant_info.ssn</th>\n",
       "      <th>applicant_info.ip_address</th>\n",
       "      <th>applicant_info.gender</th>\n",
       "      <th>applicant_info.date_of_birth</th>\n",
       "      <th>applicant_info.zip_code</th>\n",
       "      <th>financials.annual_income</th>\n",
       "      <th>...</th>\n",
       "      <th>spending_Fitness</th>\n",
       "      <th>spending_Gambling</th>\n",
       "      <th>spending_Groceries</th>\n",
       "      <th>spending_Healthcare</th>\n",
       "      <th>spending_Insurance</th>\n",
       "      <th>spending_Rent</th>\n",
       "      <th>spending_Shopping</th>\n",
       "      <th>spending_Transportation</th>\n",
       "      <th>spending_Travel</th>\n",
       "      <th>spending_Utilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>app_200</td>\n",
       "      <td>2024-01-15T00:00:00Z</td>\n",
       "      <td>Jerry Smith</td>\n",
       "      <td>jerry.smith17@hotmail.com</td>\n",
       "      <td>596-64-4340</td>\n",
       "      <td>192.168.48.155</td>\n",
       "      <td>Male</td>\n",
       "      <td>2001-03-09</td>\n",
       "      <td>10036</td>\n",
       "      <td>73000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>790</td>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brandon Walker</td>\n",
       "      <td>brandon.walker2@yahoo.com</td>\n",
       "      <td>425-69-4784</td>\n",
       "      <td>10.1.102.112</td>\n",
       "      <td>M</td>\n",
       "      <td>1992-03-31</td>\n",
       "      <td>10032</td>\n",
       "      <td>78000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scott Moore</td>\n",
       "      <td>scott.moore94@mail.com</td>\n",
       "      <td>370-78-5178</td>\n",
       "      <td>10.240.193.250</td>\n",
       "      <td>Male</td>\n",
       "      <td>1989-10-24</td>\n",
       "      <td>10075</td>\n",
       "      <td>61000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>app_024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thomas Lee</td>\n",
       "      <td>thomas.lee6@protonmail.com</td>\n",
       "      <td>194-35-1833</td>\n",
       "      <td>192.168.175.67</td>\n",
       "      <td>Male</td>\n",
       "      <td>1983-04-25</td>\n",
       "      <td>10077</td>\n",
       "      <td>103000</td>\n",
       "      <td>...</td>\n",
       "      <td>575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>app_184</td>\n",
       "      <td>2024-01-15T00:00:00Z</td>\n",
       "      <td>Brian Rodriguez</td>\n",
       "      <td>brian.rodriguez86@aol.com</td>\n",
       "      <td>480-41-2475</td>\n",
       "      <td>172.29.125.105</td>\n",
       "      <td>M</td>\n",
       "      <td>1999-05-21</td>\n",
       "      <td>10080</td>\n",
       "      <td>57000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       _id  processing_timestamp applicant_info.full_name  \\\n",
       "0  app_200  2024-01-15T00:00:00Z              Jerry Smith   \n",
       "1  app_037                   NaN           Brandon Walker   \n",
       "2  app_215                   NaN              Scott Moore   \n",
       "3  app_024                   NaN               Thomas Lee   \n",
       "4  app_184  2024-01-15T00:00:00Z          Brian Rodriguez   \n",
       "\n",
       "         applicant_info.email applicant_info.ssn applicant_info.ip_address  \\\n",
       "0   jerry.smith17@hotmail.com        596-64-4340            192.168.48.155   \n",
       "1   brandon.walker2@yahoo.com        425-69-4784              10.1.102.112   \n",
       "2      scott.moore94@mail.com        370-78-5178            10.240.193.250   \n",
       "3  thomas.lee6@protonmail.com        194-35-1833            192.168.175.67   \n",
       "4   brian.rodriguez86@aol.com        480-41-2475            172.29.125.105   \n",
       "\n",
       "  applicant_info.gender applicant_info.date_of_birth applicant_info.zip_code  \\\n",
       "0                  Male                   2001-03-09                   10036   \n",
       "1                     M                   1992-03-31                   10032   \n",
       "2                  Male                   1989-10-24                   10075   \n",
       "3                  Male                   1983-04-25                   10077   \n",
       "4                     M                   1999-05-21                   10080   \n",
       "\n",
       "  financials.annual_income  ...  spending_Fitness  spending_Gambling  \\\n",
       "0                    73000  ...                 0                  0   \n",
       "1                    78000  ...                 0                  0   \n",
       "2                    61000  ...                 0                  0   \n",
       "3                   103000  ...               575                  0   \n",
       "4                    57000  ...                 0                  0   \n",
       "\n",
       "   spending_Groceries  spending_Healthcare spending_Insurance spending_Rent  \\\n",
       "0                   0                    0                  0           790   \n",
       "1                   0                  243                  0           608   \n",
       "2                   0                    0                  0           109   \n",
       "3                   0                    0                  0             0   \n",
       "4                   0                    0                  0             0   \n",
       "\n",
       "   spending_Shopping  spending_Transportation  spending_Travel  \\\n",
       "0                480                        0                0   \n",
       "1                  0                        0                0   \n",
       "2                  0                        0                0   \n",
       "3                  0                        0                0   \n",
       "4                  0                        0                0   \n",
       "\n",
       "  spending_Utilities  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== PHASE 1: DATA INGESTION & ADVANCED FLATTENING ===\")\n",
    "file_path = '../data/raw/raw_credit_applications.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    raw_data = json.load(file)\n",
    "\n",
    "# 1. Standard Flattening\n",
    "df = pd.json_normalize(raw_data)\n",
    "\n",
    "# 2. Advanced Flattening: Explode spending_behavior immediately\n",
    "if 'spending_behavior' in df.columns:\n",
    "    print(\"Unpacking nested spending behaviors...\")\n",
    "    exploded = df.explode('spending_behavior')\n",
    "    \n",
    "    # Extract category and amount\n",
    "    exploded['spend_category'] = exploded['spending_behavior'].apply(lambda x: x.get('category') if isinstance(x, dict) else None)\n",
    "    exploded['spend_amount'] = exploded['spending_behavior'].apply(lambda x: x.get('amount') if isinstance(x, dict) else 0)\n",
    "    \n",
    "    # Pivot into separate columns\n",
    "    spending_pivot = exploded.pivot_table(\n",
    "        index='_id', \n",
    "        columns='spend_category', \n",
    "        values='spend_amount', \n",
    "        aggfunc='sum',\n",
    "        fill_value=0\n",
    "    )\n",
    "    spending_pivot.columns = [f'spending_{col}' for col in spending_pivot.columns]\n",
    "    \n",
    "    # Merge back and drop the original nested column\n",
    "    df = df.merge(spending_pivot, on='_id', how='left')\n",
    "    df.drop(columns=['spending_behavior'], inplace=True)\n",
    "    \n",
    "    # Ensure any missing spending values are set to 0\n",
    "    for col in spending_pivot.columns:\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "print(\"Data successfully loaded and flattened.\")\n",
    "print(f\"Dataset Shape: {df.shape[0]} records and {df.shape[1]} attributes.\")\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cee78f",
   "metadata": {},
   "source": [
    "## Phase 2: Systematic Data Profiling (Discovery)\n",
    "In the real world, we cannot assume we know the data's flaws. We must build systematic checks to discover issues across the four dimensions of Data Quality.\n",
    "\n",
    "1. **Completeness Profiler**: Standard `.isnull()` checks, plus a scanner for \"hidden\" nulls (empty strings, whitespace, 'N/A'). Furthermore we run a check to see if there are any useless columns (columns that have exactly 1 unique value)\n",
    "2. **Consistency Profiler**: Checking data types against expected schemas and analyzing unique values in categorical fields to spot variations (e.g., 'M' vs 'Male').\n",
    "3. **Validity & Accuracy Profiler**: Using statistical summaries to find impossible values (e.g., negative ages) and checking for logical duplicates (e.g., same SSN for different users)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ae9a3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1. COMPLETENESS DISCOVERY ===\n",
      "Columns with missing data detected:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standard Nulls</th>\n",
       "      <th>Hidden Nulls (Empty Strings)</th>\n",
       "      <th>Total Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>notes</th>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.annual_salary</th>\n",
       "      <td>497</td>\n",
       "      <td>0</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_purpose</th>\n",
       "      <td>452</td>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>processing_timestamp</th>\n",
       "      <td>440</td>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.rejection_reason</th>\n",
       "      <td>292</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.approved_amount</th>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.interest_rate</th>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.email</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.ip_address</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.ssn</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.annual_income</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.date_of_birth</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.gender</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applicant_info.zip_code</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Standard Nulls  Hidden Nulls (Empty Strings)  \\\n",
       "notes                                    500                             0   \n",
       "financials.annual_salary                 497                             0   \n",
       "loan_purpose                             452                             0   \n",
       "processing_timestamp                     440                             0   \n",
       "decision.rejection_reason                292                             0   \n",
       "decision.approved_amount                 210                             0   \n",
       "decision.interest_rate                   210                             0   \n",
       "applicant_info.email                       0                             7   \n",
       "applicant_info.ip_address                  5                             0   \n",
       "applicant_info.ssn                         5                             0   \n",
       "financials.annual_income                   5                             0   \n",
       "applicant_info.date_of_birth               1                             4   \n",
       "applicant_info.gender                      1                             2   \n",
       "applicant_info.zip_code                    1                             1   \n",
       "\n",
       "                              Total Missing  \n",
       "notes                                   500  \n",
       "financials.annual_salary                497  \n",
       "loan_purpose                            452  \n",
       "processing_timestamp                    440  \n",
       "decision.rejection_reason               292  \n",
       "decision.approved_amount                210  \n",
       "decision.interest_rate                  210  \n",
       "applicant_info.email                      7  \n",
       "applicant_info.ip_address                 5  \n",
       "applicant_info.ssn                        5  \n",
       "financials.annual_income                  5  \n",
       "applicant_info.date_of_birth              5  \n",
       "applicant_info.gender                     3  \n",
       "applicant_info.zip_code                   2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No zero-variance columns found.\n",
      "\n",
      "=== 2. CONSISTENCY DISCOVERY ===\n",
      "Data Types Overview:\n",
      "financials.annual_income    object\n",
      "dtype: object\n",
      "\n",
      "Unique values in 'applicant_info.gender':\n",
      "<StringArray>\n",
      "['Male', 'M', 'F', 'Female', '']\n",
      "Length: 5, dtype: str\n",
      "\n",
      "Unique values in 'decision.rejection_reason':\n",
      "<StringArray>\n",
      "[       'algorithm_risk_score', 'insufficient_credit_history',\n",
      "              'high_dti_ratio',                  'low_income']\n",
      "Length: 4, dtype: str\n",
      "\n",
      "=== 3. VALIDITY & ACCURACY DISCOVERY ===\n",
      "Statistical Summary for Numeric Columns (Look at min/max):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>financials.credit_history_months</th>\n",
       "      <td>-10.00</td>\n",
       "      <td>133.00</td>\n",
       "      <td>50.402390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.debt_to_income</th>\n",
       "      <td>0.05</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.246195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.savings_balance</th>\n",
       "      <td>-5000.00</td>\n",
       "      <td>88078.00</td>\n",
       "      <td>29493.503984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.interest_rate</th>\n",
       "      <td>2.50</td>\n",
       "      <td>6.50</td>\n",
       "      <td>4.564726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision.approved_amount</th>\n",
       "      <td>15000.00</td>\n",
       "      <td>80000.00</td>\n",
       "      <td>47845.890411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financials.annual_salary</th>\n",
       "      <td>45000.00</td>\n",
       "      <td>94000.00</td>\n",
       "      <td>69200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spending_Adult Entertainment</th>\n",
       "      <td>0.00</td>\n",
       "      <td>848.00</td>\n",
       "      <td>5.888446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spending_Alcohol</th>\n",
       "      <td>0.00</td>\n",
       "      <td>757.00</td>\n",
       "      <td>10.454183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spending_Dining</th>\n",
       "      <td>0.00</td>\n",
       "      <td>936.00</td>\n",
       "      <td>64.023904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spending_Education</th>\n",
       "      <td>0.00</td>\n",
       "      <td>889.00</td>\n",
       "      <td>63.701195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spending_Entertainment</th>\n",
       "      <td>0.00</td>\n",
       "      <td>883.00</td>\n",
       "      <td>71.141434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spending_Fitness</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1152.00</td>\n",
       "      <td>66.701195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spending_Gambling</th>\n",
       "      <td>0.00</td>\n",
       "      <td>751.00</td>\n",
       "      <td>6.374502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spending_Groceries</th>\n",
       "      <td>0.00</td>\n",
       "      <td>885.00</td>\n",
       "      <td>63.163347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spending_Healthcare</th>\n",
       "      <td>0.00</td>\n",
       "      <td>897.00</td>\n",
       "      <td>61.141434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spending_Insurance</th>\n",
       "      <td>0.00</td>\n",
       "      <td>890.00</td>\n",
       "      <td>64.705179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spending_Rent</th>\n",
       "      <td>0.00</td>\n",
       "      <td>897.00</td>\n",
       "      <td>61.533865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spending_Shopping</th>\n",
       "      <td>0.00</td>\n",
       "      <td>887.00</td>\n",
       "      <td>49.091633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spending_Transportation</th>\n",
       "      <td>0.00</td>\n",
       "      <td>899.00</td>\n",
       "      <td>53.348606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spending_Travel</th>\n",
       "      <td>0.00</td>\n",
       "      <td>888.00</td>\n",
       "      <td>78.629482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spending_Utilities</th>\n",
       "      <td>0.00</td>\n",
       "      <td>881.00</td>\n",
       "      <td>75.486056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       min       max          mean\n",
       "financials.credit_history_months    -10.00    133.00     50.402390\n",
       "financials.debt_to_income             0.05      1.85      0.246195\n",
       "financials.savings_balance        -5000.00  88078.00  29493.503984\n",
       "decision.interest_rate                2.50      6.50      4.564726\n",
       "decision.approved_amount          15000.00  80000.00  47845.890411\n",
       "financials.annual_salary          45000.00  94000.00  69200.000000\n",
       "spending_Adult Entertainment          0.00    848.00      5.888446\n",
       "spending_Alcohol                      0.00    757.00     10.454183\n",
       "spending_Dining                       0.00    936.00     64.023904\n",
       "spending_Education                    0.00    889.00     63.701195\n",
       "spending_Entertainment                0.00    883.00     71.141434\n",
       "spending_Fitness                      0.00   1152.00     66.701195\n",
       "spending_Gambling                     0.00    751.00      6.374502\n",
       "spending_Groceries                    0.00    885.00     63.163347\n",
       "spending_Healthcare                   0.00    897.00     61.141434\n",
       "spending_Insurance                    0.00    890.00     64.705179\n",
       "spending_Rent                         0.00    897.00     61.533865\n",
       "spending_Shopping                     0.00    887.00     49.091633\n",
       "spending_Transportation               0.00    899.00     53.348606\n",
       "spending_Travel                       0.00    888.00     78.629482\n",
       "spending_Utilities                    0.00    881.00     75.486056"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 3 unique SSNs that are shared across 11 different records!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 1. COMPLETENESS DISCOVERY ===\")\n",
    "# Standard nulls\n",
    "standard_nulls = df.isnull().sum()\n",
    "\n",
    "# Scanner for hidden nulls (strings that are just spaces or empty)\n",
    "hidden_nulls = df.map(lambda x: str(x).strip() == '').sum()\n",
    "\n",
    "completeness_df = pd.DataFrame({\n",
    "    'Standard Nulls': standard_nulls,\n",
    "    'Hidden Nulls (Empty Strings)': hidden_nulls,\n",
    "    'Total Missing': standard_nulls + hidden_nulls\n",
    "})\n",
    "print(\"Columns with missing data detected:\")\n",
    "display(completeness_df[completeness_df['Total Missing'] > 0].sort_values(by='Total Missing', ascending=False))\n",
    "\n",
    "# Check if any column has exactly 1 unique value (e.g., all 0s)\n",
    "zero_variance_cols = [col for col in df.columns if df[col].nunique() <= 1]\n",
    "\n",
    "if zero_variance_cols:\n",
    "    print(f\"Found {len(zero_variance_cols)} columns with zero variance (no useful information):\")\n",
    "    print(zero_variance_cols)\n",
    "else:\n",
    "    print(\"No zero-variance columns found.\")\n",
    "\n",
    "\n",
    "print(\"\\n=== 2. CONSISTENCY DISCOVERY ===\")\n",
    "# Check data types to find mismatches (e.g., numbers stored as strings)\n",
    "print(\"Data Types Overview:\")\n",
    "print(df.dtypes[df.dtypes == 'object']) # Focusing on object/string columns\n",
    "\n",
    "# Check unique values for categorical columns to spot formatting inconsistencies\n",
    "categorical_cols = ['applicant_info.gender', 'decision.rejection_reason']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\nUnique values in '{col}':\")\n",
    "        print(df[col].dropna().unique())\n",
    "\n",
    "\n",
    "print(\"\\n=== 3. VALIDITY & ACCURACY DISCOVERY ===\")\n",
    "# Statistical summary to spot impossible min/max values (e.g., negatives)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "print(\"Statistical Summary for Numeric Columns (Look at min/max):\")\n",
    "display(df[numeric_cols].describe().T[['min', 'max', 'mean']])\n",
    "\n",
    "# Logical Duplicates Check (SSN is a primary identifier, it should be unique)\n",
    "if 'applicant_info.ssn' in df.columns:\n",
    "    duplicate_ssns = df[df.duplicated(subset=['applicant_info.ssn'], keep=False)]\n",
    "    print(f\"\\nFound {duplicate_ssns['applicant_info.ssn'].nunique()} unique SSNs that are shared across {len(duplicate_ssns)} different records!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b963bd2c",
   "metadata": {},
   "source": [
    "### Phase 2.5: Deep Dive Profiling (Domain-Specific Checks)\n",
    "To ensure maximum Data Quality, we must go beyond basic statistical profiling and check domain-specific business rules:\n",
    "\n",
    "4. **Format Validation**: Using Regex to ensure SSNs, Emails, and IPs follow standard patterns.\n",
    "5. **Cross-Field Logic**: Ensuring the loan decision logic (`approved` vs `rejected` fields) does not contradict itself.\n",
    "6. **Nested Array Inspection**: Unpacking the `spending_behavior` array to check for anomalous spending amounts.\n",
    "7. **Temporal Logic**: Checking for impossible birth dates.\n",
    "8. **Final verification**: Checking for exact duplicate records, inconsistent data types and date formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "838e644d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 4. FORMAT VALIDITY (REGEX CHECKS) ===\n",
      "Found 11 malformed emails.\n",
      "26                           \n",
      "138    mike johnson@gmail.com\n",
      "181     test.user.outlook.com\n",
      "187                          \n",
      "275                          \n",
      "Name: applicant_info.email, dtype: str\n",
      "\n",
      "Found 0 malformed SSNs.\n",
      "\n",
      "=== 5. CROSS-COLUMN LOGICAL VALIDITY ===\n",
      "Contradiction (Approved but rejected): 0 rows\n",
      "Contradiction (Rejected but has approved amount): 0 rows\n",
      "\n",
      "=== 6. PIVOTED DATA INSPECTION (SPENDING BEHAVIOR) ===\n",
      "Total negative spending amounts found across all categories: 0\n",
      "\n",
      "=== 7. TEMPORAL ACCURACY ===\n",
      "Found 0 birth dates in the future.\n",
      "Found 0 applicants appearing to be underage (< 18).\n",
      "\n",
      "=== 8. FINANCIAL VALIDITY (NEGATIVE BALANCES/RATIOS) ===\n",
      "  -> ALARM: Found 1 negative values in 'financials.savings_balance'!\n",
      "  -> ALARM: Found 2 negative values in 'financials.credit_history_months'!\n",
      "\n",
      "=== 9. FINAL VERIFICATION ===\n",
      "Found 4 exact duplicate records.\n",
      "\n",
      "Row-by-row data types in 'annual_income':\n",
      "financials.annual_income\n",
      "<class 'int'>      488\n",
      "<class 'str'>        8\n",
      "<class 'float'>      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of Inconsistent Date Formats in 'date_of_birth':\n",
      "<StringArray>\n",
      "['2001-03-09', '1992-03-31', '14/02/1982', '28/01/1990']\n",
      "Length: 4, dtype: str\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 4. FORMAT VALIDITY (REGEX CHECKS) ===\")\n",
    "# Check for malformed emails\n",
    "email_regex = r\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"\n",
    "if 'applicant_info.email' in df.columns:\n",
    "    valid_emails = df['applicant_info.email'].dropna().apply(lambda x: bool(re.match(email_regex, str(x))))\n",
    "    invalid_emails = df['applicant_info.email'].dropna()[~valid_emails]\n",
    "    print(f\"Found {len(invalid_emails)} malformed emails.\")\n",
    "    if len(invalid_emails) > 0: print(invalid_emails.head())\n",
    "\n",
    "# Check for malformed SSNs (expecting XXX-XX-XXXX)\n",
    "ssn_regex = r\"^\\d{3}-\\d{2}-\\d{4}$\"\n",
    "if 'applicant_info.ssn' in df.columns:\n",
    "    valid_ssns = df['applicant_info.ssn'].dropna().apply(lambda x: bool(re.match(ssn_regex, str(x))))\n",
    "    invalid_ssns = df['applicant_info.ssn'].dropna()[~valid_ssns]\n",
    "    print(f\"\\nFound {len(invalid_ssns)} malformed SSNs.\")\n",
    "\n",
    "\n",
    "print(\"\\n=== 5. CROSS-COLUMN LOGICAL VALIDITY ===\")\n",
    "# Contradiction: Loan approved BUT has a rejection reason\n",
    "contradiction_1 = df[(df['decision.loan_approved'] == True) & (df['decision.rejection_reason'].notnull())]\n",
    "print(f\"Contradiction (Approved but rejected): {len(contradiction_1)} rows\")\n",
    "\n",
    "# Contradiction: Loan rejected BUT has an approved amount\n",
    "contradiction_2 = df[(df['decision.loan_approved'] == False) & (df['decision.approved_amount'].notnull())]\n",
    "print(f\"Contradiction (Rejected but has approved amount): {len(contradiction_2)} rows\")\n",
    "\n",
    "\n",
    "print(\"\\n=== 6. PIVOTED DATA INSPECTION (SPENDING BEHAVIOR) ===\")\n",
    "# Since we exploded and pivoted the spending in Phase 1, \n",
    "# we now check all the new numerical spending columns for impossible negative values.\n",
    "spending_cols = [col for col in df.columns if str(col).startswith('spending_')]\n",
    "total_negative_spends = 0\n",
    "\n",
    "for col in spending_cols:\n",
    "    # Count how many negative values exist in this specific spending category\n",
    "    negative_count = (df[col] < 0).sum()\n",
    "    if negative_count > 0:\n",
    "        print(f\"  -> Found {negative_count} negative amounts in '{col}'\")\n",
    "        total_negative_spends += negative_count\n",
    "\n",
    "print(f\"Total negative spending amounts found across all categories: {total_negative_spends}\")\n",
    "\n",
    "\n",
    "print(\"\\n=== 7. TEMPORAL ACCURACY ===\")\n",
    "if 'applicant_info.date_of_birth' in df.columns:\n",
    "    # Convert to datetime just for checking (handling mixed formats safely with coerce to catch unparseable ones)\n",
    "    temp_dob = pd.to_datetime(df['applicant_info.date_of_birth'], format='mixed', errors='coerce')\n",
    "    \n",
    "    # Check for dates in the future\n",
    "    future_dates = temp_dob[temp_dob > pd.Timestamp.now()]\n",
    "    print(f\"Found {len(future_dates)} birth dates in the future.\")\n",
    "    \n",
    "    # Check for unrealistic ages (e.g., born after 2008 -> under 18)\n",
    "    underage = temp_dob[temp_dob > pd.Timestamp('2008-01-01')]\n",
    "    print(f\"Found {len(underage)} applicants appearing to be underage (< 18).\")\n",
    "\n",
    "\n",
    "print(\"\\n=== 8. FINANCIAL VALIDITY (NEGATIVE BALANCES/RATIOS) ===\")\n",
    "# List of financial columns that strictly cannot be negative\n",
    "financial_cols = [\n",
    "    'financials.savings_balance', \n",
    "    'financials.debt_to_income', \n",
    "    'financials.credit_history_months'\n",
    "]\n",
    "\n",
    "for col in financial_cols:\n",
    "    if col in df.columns:\n",
    "        # We use pd.to_numeric with coerce just in case there are still strings\n",
    "        temp_col = pd.to_numeric(df[col], errors='coerce')\n",
    "        negative_count = (temp_col < 0).sum()\n",
    "        if negative_count > 0:\n",
    "            print(f\"  -> ALARM: Found {negative_count} negative values in '{col}'!\")\n",
    "\n",
    "\n",
    "print(\"\\n=== 9. FINAL VERIFICATION ===\")\n",
    "\n",
    "# 1. Exact Duplicate Records\n",
    "# Checking if any entire row is a 1:1 copy of another\n",
    "exact_duplicates = df[df.duplicated(subset=[\"_id\"], keep=False)]\n",
    "print(f\"Found {len(exact_duplicates)} exact duplicate records.\")\n",
    "\n",
    "# 2. Inconsistent Data Types Across Records\n",
    "# Checking the Python type of each individual cell in a problematic column\n",
    "if 'financials.annual_income' in df.columns:\n",
    "    print(\"\\nRow-by-row data types in 'annual_income':\")\n",
    "    type_counts = df['financials.annual_income'].dropna().apply(type).value_counts()\n",
    "    print(type_counts)\n",
    "\n",
    "# 3. Inconsistent Date Formats\n",
    "# Printing a sample to visually prove the formatting clash\n",
    "if 'applicant_info.date_of_birth' in df.columns:\n",
    "    print(\"\\nSample of Inconsistent Date Formats in 'date_of_birth':\")\n",
    "    # Grabbing a mix of rows to show the discrepancy\n",
    "    sample_dates = df['applicant_info.date_of_birth'].dropna().iloc[[0, 1, 5, 6]].values\n",
    "    print(sample_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d116a",
   "metadata": {},
   "source": [
    "## Phase 3: Data Remediation (Cleaning Pipeline)\n",
    "Based on our systematic profiling, we will now apply a data cleaning pipeline to resolve all identified issues, ensuring the dataset is ready for the Bias Detection and Privacy phases.\n",
    "\n",
    "**Remediation Strategies by Dimension:**\n",
    "1. **Accuracy (Duplicates)**: Drop exact row duplicates. Because of unhashable lists, we will use string conversion for the duplication mask.\n",
    "2. **Consistency (Formatting & Schema)**: \n",
    "   - Standardize `gender` to 'Male' and 'Female'.\n",
    "   - Consolidate the misaligned `annual_salary` column into `annual_income`.\n",
    "   - Cast `annual_income` to numeric float values.\n",
    "   - Standardize `date_of_birth` to uniform pandas `datetime` objects.\n",
    "3. **Validity (Impossible Values)**:\n",
    "   - Convert negative values in core financial columns to `NaN` (treating them as data entry errors).\n",
    "   - Clean the nested `spending_behavior` arrays by removing dictionaries with negative amounts.\n",
    "4. **Completeness (Imputation)**:\n",
    "   - Fill missing numeric values (like the newly created NaNs in credit history or missing income) with the median to avoid losing records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adbf692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Data Remediation Pipeline...\n",
      "Dropped 2 exact duplicate rows.\n",
      "Merged 'annual_salary' into 'annual_income' and dropped redundant column.\n",
      "Cast 'annual_income' to numeric.\n",
      "Standardized 'gender' formats.\n",
      "Standardized 'date_of_birth' to datetime objects.\n",
      "Fixing impossible validity errors...\n",
      "✔ Replaced 1 negative values in 'financials.savings_balance' with NaN.\n",
      "✔ Replaced 2 negative values in 'financials.credit_history_months' with NaN.\n",
      "Imputed missing numeric values (including fixed negative balances) with column medians.\n",
      "\n",
      "=== REMEDIATION COMPLETE ===\n",
      "Final Cleaned Dataset Shape: 500 records and 34 attributes.\n",
      "<class 'pandas.DataFrame'>\n",
      "Index: 500 entries, 0 to 501\n",
      "Data columns (total 34 columns):\n",
      " #   Column                            Non-Null Count  Dtype         \n",
      "---  ------                            --------------  -----         \n",
      " 0   _id                               500 non-null    str           \n",
      " 1   processing_timestamp              62 non-null     str           \n",
      " 2   applicant_info.full_name          500 non-null    str           \n",
      " 3   applicant_info.email              500 non-null    str           \n",
      " 4   applicant_info.ssn                496 non-null    str           \n",
      " 5   applicant_info.ip_address         496 non-null    str           \n",
      " 6   applicant_info.gender             500 non-null    str           \n",
      " 7   applicant_info.date_of_birth      496 non-null    datetime64[us]\n",
      " 8   applicant_info.zip_code           500 non-null    str           \n",
      " 9   financials.annual_income          500 non-null    float64       \n",
      " 10  financials.credit_history_months  500 non-null    float64       \n",
      " 11  financials.debt_to_income         500 non-null    float64       \n",
      " 12  financials.savings_balance        500 non-null    float64       \n",
      " 13  decision.loan_approved            500 non-null    bool          \n",
      " 14  decision.rejection_reason         208 non-null    str           \n",
      " 15  loan_purpose                      50 non-null     str           \n",
      " 16  decision.interest_rate            292 non-null    float64       \n",
      " 17  decision.approved_amount          292 non-null    float64       \n",
      " 18  notes                             0 non-null      str           \n",
      " 19  spending_Adult Entertainment      500 non-null    int64         \n",
      " 20  spending_Alcohol                  500 non-null    int64         \n",
      " 21  spending_Dining                   500 non-null    int64         \n",
      " 22  spending_Education                500 non-null    int64         \n",
      " 23  spending_Entertainment            500 non-null    int64         \n",
      " 24  spending_Fitness                  500 non-null    int64         \n",
      " 25  spending_Gambling                 500 non-null    int64         \n",
      " 26  spending_Groceries                500 non-null    int64         \n",
      " 27  spending_Healthcare               500 non-null    int64         \n",
      " 28  spending_Insurance                500 non-null    int64         \n",
      " 29  spending_Rent                     500 non-null    int64         \n",
      " 30  spending_Shopping                 500 non-null    int64         \n",
      " 31  spending_Transportation           500 non-null    int64         \n",
      " 32  spending_Travel                   500 non-null    int64         \n",
      " 33  spending_Utilities                500 non-null    int64         \n",
      "dtypes: bool(1), datetime64[us](1), float64(6), int64(15), str(11)\n",
      "memory usage: 133.3 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>processing_timestamp</th>\n",
       "      <th>applicant_info.full_name</th>\n",
       "      <th>applicant_info.email</th>\n",
       "      <th>applicant_info.ssn</th>\n",
       "      <th>applicant_info.ip_address</th>\n",
       "      <th>applicant_info.gender</th>\n",
       "      <th>applicant_info.date_of_birth</th>\n",
       "      <th>applicant_info.zip_code</th>\n",
       "      <th>financials.annual_income</th>\n",
       "      <th>...</th>\n",
       "      <th>spending_Fitness</th>\n",
       "      <th>spending_Gambling</th>\n",
       "      <th>spending_Groceries</th>\n",
       "      <th>spending_Healthcare</th>\n",
       "      <th>spending_Insurance</th>\n",
       "      <th>spending_Rent</th>\n",
       "      <th>spending_Shopping</th>\n",
       "      <th>spending_Transportation</th>\n",
       "      <th>spending_Travel</th>\n",
       "      <th>spending_Utilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>app_200</td>\n",
       "      <td>2024-01-15T00:00:00Z</td>\n",
       "      <td>Jerry Smith</td>\n",
       "      <td>jerry.smith17@hotmail.com</td>\n",
       "      <td>596-64-4340</td>\n",
       "      <td>192.168.48.155</td>\n",
       "      <td>Male</td>\n",
       "      <td>2001-03-09</td>\n",
       "      <td>10036</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>790</td>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brandon Walker</td>\n",
       "      <td>brandon.walker2@yahoo.com</td>\n",
       "      <td>425-69-4784</td>\n",
       "      <td>10.1.102.112</td>\n",
       "      <td>Male</td>\n",
       "      <td>1992-03-31</td>\n",
       "      <td>10032</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scott Moore</td>\n",
       "      <td>scott.moore94@mail.com</td>\n",
       "      <td>370-78-5178</td>\n",
       "      <td>10.240.193.250</td>\n",
       "      <td>Male</td>\n",
       "      <td>1989-10-24</td>\n",
       "      <td>10075</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>app_024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thomas Lee</td>\n",
       "      <td>thomas.lee6@protonmail.com</td>\n",
       "      <td>194-35-1833</td>\n",
       "      <td>192.168.175.67</td>\n",
       "      <td>Male</td>\n",
       "      <td>1983-04-25</td>\n",
       "      <td>10077</td>\n",
       "      <td>103000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>app_184</td>\n",
       "      <td>2024-01-15T00:00:00Z</td>\n",
       "      <td>Brian Rodriguez</td>\n",
       "      <td>brian.rodriguez86@aol.com</td>\n",
       "      <td>480-41-2475</td>\n",
       "      <td>172.29.125.105</td>\n",
       "      <td>Male</td>\n",
       "      <td>1999-05-21</td>\n",
       "      <td>10080</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       _id  processing_timestamp applicant_info.full_name  \\\n",
       "0  app_200  2024-01-15T00:00:00Z              Jerry Smith   \n",
       "1  app_037                   NaN           Brandon Walker   \n",
       "2  app_215                   NaN              Scott Moore   \n",
       "3  app_024                   NaN               Thomas Lee   \n",
       "4  app_184  2024-01-15T00:00:00Z          Brian Rodriguez   \n",
       "\n",
       "         applicant_info.email applicant_info.ssn applicant_info.ip_address  \\\n",
       "0   jerry.smith17@hotmail.com        596-64-4340            192.168.48.155   \n",
       "1   brandon.walker2@yahoo.com        425-69-4784              10.1.102.112   \n",
       "2      scott.moore94@mail.com        370-78-5178            10.240.193.250   \n",
       "3  thomas.lee6@protonmail.com        194-35-1833            192.168.175.67   \n",
       "4   brian.rodriguez86@aol.com        480-41-2475            172.29.125.105   \n",
       "\n",
       "  applicant_info.gender applicant_info.date_of_birth applicant_info.zip_code  \\\n",
       "0                  Male                   2001-03-09                   10036   \n",
       "1                  Male                   1992-03-31                   10032   \n",
       "2                  Male                   1989-10-24                   10075   \n",
       "3                  Male                   1983-04-25                   10077   \n",
       "4                  Male                   1999-05-21                   10080   \n",
       "\n",
       "   financials.annual_income  ...  spending_Fitness  spending_Gambling  \\\n",
       "0                   73000.0  ...                 0                  0   \n",
       "1                   78000.0  ...                 0                  0   \n",
       "2                   61000.0  ...                 0                  0   \n",
       "3                  103000.0  ...               575                  0   \n",
       "4                   57000.0  ...                 0                  0   \n",
       "\n",
       "   spending_Groceries  spending_Healthcare spending_Insurance spending_Rent  \\\n",
       "0                   0                    0                  0           790   \n",
       "1                   0                  243                  0           608   \n",
       "2                   0                    0                  0           109   \n",
       "3                   0                    0                  0             0   \n",
       "4                   0                    0                  0             0   \n",
       "\n",
       "   spending_Shopping  spending_Transportation spending_Travel  \\\n",
       "0                480                        0               0   \n",
       "1                  0                        0               0   \n",
       "2                  0                        0               0   \n",
       "3                  0                        0               0   \n",
       "4                  0                        0               0   \n",
       "\n",
       "   spending_Utilities  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Starting Data Remediation Pipeline...\")\n",
    "\n",
    "# Make a copy to preserve the original flattened dataframe\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 1. ACCURACY: Drop Exact Duplicates\n",
    "# We use the string casting trick to find and drop exact duplicate rows\n",
    "duplicate_mask = df_clean.duplicated(subset=[\"_id\"], keep='first')\n",
    "df_clean = df_clean[~duplicate_mask]\n",
    "print(f\"Dropped {duplicate_mask.sum()} exact duplicate rows.\")\n",
    "\n",
    "\n",
    "# 2. CONSISTENCY: Schema, Types, and Formatting\n",
    "# Schema consolidation\n",
    "if 'financials.annual_salary' in df_clean.columns:\n",
    "    df_clean['financials.annual_income'] = df_clean['financials.annual_income'].fillna(df_clean['financials.annual_salary'])\n",
    "    df_clean.drop(columns=['financials.annual_salary'], inplace=True)\n",
    "    print(\"Merged 'annual_salary' into 'annual_income' and dropped redundant column.\")\n",
    "\n",
    "# Type casting\n",
    "df_clean['financials.annual_income'] = pd.to_numeric(df_clean['financials.annual_income'], errors='coerce')\n",
    "print(\"Cast 'annual_income' to numeric.\")\n",
    "\n",
    "# Gender standardization\n",
    "df_clean['applicant_info.gender'] = df_clean['applicant_info.gender'].replace({'M': 'Male', 'F': 'Female'})\n",
    "print(\"Standardized 'gender' formats.\")\n",
    "\n",
    "# Date standardization\n",
    "df_clean['applicant_info.date_of_birth'] = pd.to_datetime(df_clean['applicant_info.date_of_birth'], format='mixed', errors='coerce')\n",
    "print(\"Standardized 'date_of_birth' to datetime objects.\")\n",
    "\n",
    "\n",
    "# 3. VALIDITY: Impossible Values\n",
    "print(\"Fixing impossible validity errors...\")\n",
    "\n",
    "# Fix negative values in core financial columns by setting them to NaN (to be imputed later)\n",
    "financial_cols_to_check = [\n",
    "    'financials.savings_balance', \n",
    "    'financials.debt_to_income', \n",
    "    'financials.credit_history_months'\n",
    "]\n",
    "\n",
    "for col in financial_cols_to_check:\n",
    "    if col in df_clean.columns:\n",
    "        # Identify negative values\n",
    "        invalid_mask = df_clean[col] < 0\n",
    "        if invalid_mask.sum() > 0:\n",
    "            df_clean.loc[invalid_mask, col] = np.nan\n",
    "            print(f\"Replaced {invalid_mask.sum()} negative values in '{col}' with NaN.\")\n",
    "\n",
    "# 4. COMPLETENESS: Handling Missing Data\n",
    "# We must update our imputation list to include ALL financial columns so those new NaNs get fixed!\n",
    "numeric_cols_to_impute = [\n",
    "    'financials.annual_income', \n",
    "    'financials.credit_history_months',\n",
    "    'financials.savings_balance',\n",
    "    'financials.debt_to_income'\n",
    "]\n",
    "\n",
    "for col in numeric_cols_to_impute:\n",
    "    if col in df_clean.columns:\n",
    "        median_val = df_clean[col].median()\n",
    "        df_clean[col] = df_clean[col].fillna(median_val)\n",
    "print(\"Imputed missing numeric values (including fixed negative balances) with column medians.\")\n",
    "\n",
    "# Categorical missing values (e.g., gender, missing emails) \n",
    "# We'll label missing categorical values as 'Unknown' to explicitly track them\n",
    "df_clean['applicant_info.gender'] = df_clean['applicant_info.gender'].fillna('Unknown')\n",
    "\n",
    "print(\"\\n=== REMEDIATION COMPLETE ===\")\n",
    "print(f\"Final Cleaned Dataset Shape: {df_clean.shape[0]} records and {df_clean.shape[1]} attributes.\")\n",
    "display(df_clean.info())\n",
    "display(df_clean.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efe75026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset successfully exported to: ../data/processed/cleaned_credit_applications.json\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataset to the processed folder\n",
    "output_path = '../data/processed/cleaned_credit_applications.json'\n",
    "\n",
    "# Convert datetime back to string for JSON serialization\n",
    "df_export = df_clean.copy()\n",
    "df_export['applicant_info.date_of_birth'] = df_export['applicant_info.date_of_birth'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Export to JSON\n",
    "df_export.to_json(output_path, orient='records', indent=4)\n",
    "print(f\"Cleaned dataset successfully exported to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
